{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur thermique et visuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('base_de_données.csv')\n",
    "df_train = pd.read_csv('X_train.csv')\n",
    "df_test = pd.read_csv('X_test.csv')\n",
    "csv_thermiques_train = df_train['nom_fichier']\n",
    "indices_train = df_train['index']\n",
    "csv_thermiques_test = df_test['nom_fichier']\n",
    "indices_test = df_test['index']\n",
    "csv_thermiques = df['nom_fichier']\n",
    "csv = csv_thermiques[0]\n",
    "csv_0 = (csv.split('.'))[0]\n",
    "sift_th = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df['photo']\n",
    "images_train = df_train['photo']\n",
    "images_test = df_test['photo']\n",
    "\n",
    "\n",
    "#sift = cv2.SIFT_create(edgeThreshold=2.4,contrastThreshold=0.011)\n",
    "sift = cv2.SIFT_create(edgeThreshold=2,contrastThreshold=0.014,sigma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des descripteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "(1883, 128)\n",
      "(14398, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "buff =  cv2.imread('./Photographies pieces chaudes/' + images[0] ,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "mask = np.zeros_like(buff)\n",
    "z = np.ones((550,600))\n",
    "mask[350:900,600:1200] = z\n",
    "mask = np.uint8(mask)\n",
    "\n",
    "i=0\n",
    "for image,csv in zip(images_train,csv_thermiques_train) :\n",
    "\tnom_csv = (csv.split('.'))[0]\n",
    "\tif i==0:\n",
    "\t\timg_th = cv2.imread('./cv2_thermiques/' + nom_csv + '.png',cv2.IMREAD_GRAYSCALE)\n",
    "\t\tmask_th = np.load('./mask_thermique/'+ nom_csv + '.npy')\n",
    "\t\t\n",
    "\t\t#kp,des = sift.detectAndCompute(img,None)\n",
    "\t\tkp_th = sift_th.detect(img_th,mask = mask_th)\n",
    "\t\tkp_th,des_th = sift_th.compute(img_th,kp_th)\n",
    "\t\tdescripteurs_th = des_th\n",
    "\t\t\n",
    "\t\timg = cv2.imread('./Photographies pieces chaudes/' + image ,cv2.IMREAD_GRAYSCALE)\n",
    "\t\t#kp,des = sift.detectAndCompute(img,None)\n",
    "\t\tkp = sift.detect(img,mask = mask)\n",
    "\t\tkp,des = sift.compute(img,kp)\n",
    "\t\tdescripteurs = des\n",
    "\t\t\n",
    "\telse:\n",
    "\t\timg_th = cv2.imread('./cv2_thermiques/' + nom_csv + '.png',cv2.IMREAD_GRAYSCALE)\n",
    "\t\tmask_th = np.load('./mask_thermique/'+ nom_csv + '.npy')\n",
    "\t\t\n",
    "\t\t#kp,des = sift.detectAndCompute(img,None)\n",
    "\t\tkp_th = sift_th.detect(img_th,mask = mask_th)\n",
    "\t\tkp_th,des_th = sift_th.compute(img_th,kp_th)\t\t\n",
    "\t\tdescripteurs_th = np.concatenate((descripteurs_th,des_th),axis=0)\n",
    "\t\t\n",
    "\t\timg = cv2.imread('./Photographies pieces chaudes/' + image ,cv2.IMREAD_GRAYSCALE)\n",
    "\t\t#kp,des = sift.detectAndCompute(img,None)\n",
    "\t\tkp = sift.detect(img,mask = mask)\n",
    "\t\tkp,des = sift.compute(img,kp)\t\t\n",
    "\t\tdescripteurs = np.concatenate((descripteurs,des),axis=0)\n",
    "\t\t\n",
    "\ti+=1\n",
    "\tprint(i)\n",
    "\n",
    "descripteurs_th = np.float32(descripteurs_th)\n",
    "descripteurs = np.float32(descripteurs)\n",
    "print(descripteurs_th.shape)\n",
    "print(descripteurs.shape)\n",
    "np.save('descripteurs_th.npy',descripteurs_th)\n",
    "np.save('descripteurs.npy',descripteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation des labels (tache : non conforme (1) si q_tache>3)\n",
    "q_tache_train = df_train['q_tache'].fillna(0)\n",
    "Y_train = q_tache_train.to_numpy(np.float32)\n",
    "Y_train = (Y_train >3)\n",
    "Y_train = np.int16(Y_train)\n",
    "\n",
    "q_tache_test = df_test['q_tache'].fillna(0)\n",
    "Y_test = q_tache_test.to_numpy(np.float32)\n",
    "Y_test = (Y_test >3)\n",
    "Y_test = np.int16(Y_test)\n",
    "\n",
    "\n",
    "np.save('Y_train.npy',Y_train)\n",
    "np.save('Y_test.npy',Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des histogrammes sur les jeux  \n",
    "Sur les données visibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "(107, 500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "descripteurs = np.load('descripteurs.npy')\n",
    "descripteurs_th = np.load('descripteurs_th.npy')\n",
    "\n",
    "#Calculs des center des k means\n",
    "nbre_clusters = 500\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "ret,label,center=cv2.kmeans(descripteurs,nbre_clusters,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "np.save('center_k_means.npy',center)\n",
    "\n",
    "Y_train = np.load('Y_train.npy')\n",
    "n = Y_train.shape[0]\n",
    "X_train = np.zeros((n,nbre_clusters))\n",
    "\n",
    "center_k_means = np.load('center_k_means.npy')\n",
    "\n",
    "k=0\n",
    "for indice,image in zip(indices_train,images_train):\t\n",
    "\timg = cv2.imread('./Photographies pieces chaudes/' + image ,cv2.IMREAD_GRAYSCALE)\n",
    "\t#kp,des = sift.detectAndCompute(img,None)\n",
    "\tkp = sift.detect(img,mask = mask)\n",
    "\tkp,des = sift.compute(img,kp)\n",
    "\tnbr_des = des.shape[0]\n",
    "\tx = np.zeros((nbre_clusters,))\n",
    "\tfor elem in des:\n",
    "\t\tdistance = np.linalg.norm(center_k_means - elem,axis=1)\n",
    "\t\tj = np.argmin(distance)\n",
    "\t\tx[j]+=1\n",
    "\tx = x/nbr_des\n",
    "\tX_train[k] = x\n",
    "\tk+=1\n",
    "\tprint(k)\n",
    "\n",
    "np.save('X_train_vi.npy',X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "m = len(images)-X_train.shape[0]\n",
    "X_test = np.zeros((m,nbre_clusters))\n",
    "\n",
    "\n",
    "k=0\n",
    "for indice,image in zip(indices_test,images_test):\t\n",
    "\n",
    "\timg = cv2.imread('./Photographies pieces chaudes/' + image ,cv2.IMREAD_GRAYSCALE)\n",
    "\t#kp,des = sift.detectAndCompute(img,None)\n",
    "\tkp = sift.detect(img,mask = mask)\n",
    "\tkp,des = sift.compute(img,kp)\n",
    "\tnbr_des = des.shape[0]\n",
    "\tx = np.zeros((nbre_clusters,))\n",
    "\tfor elem in des:\n",
    "\t\tdistance = np.linalg.norm(center_k_means - elem,axis=1)\n",
    "\t\tj = np.argmin(distance)\n",
    "\t\tx[j]+=1\n",
    "\tx = x/nbr_des\n",
    "\tX_test[k] = x\n",
    "\tk+=1\n",
    "\tprint(k)\n",
    "\t\n",
    "np.save('X_test_vi.npy',X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et sur les données IR :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "(107, 7)\n"
     ]
    }
   ],
   "source": [
    "descripteurs_th = np.load('descripteurs_th.npy')\n",
    "\n",
    "#Calculs des center des k means\n",
    "nbre_clusters_th = 5 #tres petit nombre car faible nombre de features de base sur les img thermiques\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "ret,label,center_th=cv2.kmeans(descripteurs_th,nbre_clusters_th,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "np.save('center_k_means_th.npy',center_th)\n",
    "\n",
    "Y_train = np.load('Y_train.npy')\n",
    "n = Y_train.shape[0]\n",
    "X_train_th = np.zeros((n,nbre_clusters_th +2))\n",
    "\n",
    "arr_min = np.load('./array_min_max/array_min.npy')\n",
    "arr_max = np.load('./array_min_max/array_max.npy')\n",
    "\n",
    "center_k_means_th = np.load('center_k_means_th.npy')\n",
    "\n",
    "k=0\n",
    "for indice,csv in zip(indices_train , csv_thermiques_train) :\n",
    "\tnom_csv = (csv.split('.'))[0]\n",
    "\t\n",
    "\timg_th = cv2.imread('./cv2_thermiques/' + nom_csv + '.png',cv2.IMREAD_GRAYSCALE)\n",
    "\tmask_th = np.load('./mask_thermique/'+ nom_csv + '.npy')\n",
    "\t\t\n",
    "\t#kp,des = sift.detectAndCompute(img,None)\n",
    "\tkp_th = sift_th.detect(img_th,mask = mask_th)\n",
    "\tkp_th,des_th = sift_th.compute(img_th,kp_th)\n",
    "\tnbr_des = des_th.shape[0]\n",
    "\tx = np.zeros((nbre_clusters_th + 2,))\n",
    "\tfor elem in des_th:\n",
    "\t\tdistance = np.linalg.norm(center_k_means_th - elem,axis=1)\n",
    "\t\tj = np.argmin(distance)\n",
    "\t\tx[j]+=1\n",
    "\tx = x/nbr_des\n",
    "\tx[nbre_clusters_th] = arr_min[indice]\n",
    "\tx[nbre_clusters_th+1] = arr_max[indice]\n",
    "\tX_train_th[k] = x\n",
    "\tk+=1\n",
    "\tprint(k)\n",
    "\n",
    "np.save('X_train_th.npy',X_train_th)\n",
    "print(X_train_th.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "m = len(csv_thermiques)-X_train_th.shape[0]\n",
    "X_test_th = np.zeros((m,nbre_clusters_th+2))\n",
    "\n",
    "\n",
    "\n",
    "k=0\n",
    "for indice,csv in zip(indices_test , csv_thermiques_test) :\n",
    "\t\n",
    "\tnom_csv = (csv.split('.'))[0]\n",
    "\timg_th = cv2.imread('./cv2_thermiques/' + nom_csv + '.png',cv2.IMREAD_GRAYSCALE)\n",
    "\tmask_th = np.load('./mask_thermique/'+ nom_csv + '.npy')\n",
    "\t\n",
    "\t#kp,des = sift.detectAndCompute(img,None)\n",
    "\tkp_th = sift_th.detect(img_th,mask = mask_th)\n",
    "\tkp_th,des_th = sift_th.compute(img_th,kp_th)\n",
    "\tnbr_des = des_th.shape[0]\n",
    "\tx = np.zeros((nbre_clusters_th + 2,))\n",
    "\tfor elem in des_th:\n",
    "\t\tdistance = np.linalg.norm(center_k_means_th - elem,axis=1)\n",
    "\t\tj = np.argmin(distance)\n",
    "\t\tx[j]+=1\n",
    "\tx = x/nbr_des\n",
    "\tx[nbre_clusters_th] = arr_min[indice]\n",
    "\tx[nbre_clusters_th +1] = arr_max[indice]\n",
    "\tX_test_th[k] = x\n",
    "\tk+=1\n",
    "\tprint(k)\n",
    "\t\n",
    "np.save('X_test_th.npy',X_test_th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemblage des X :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 507)\n",
      "(72, 507)\n"
     ]
    }
   ],
   "source": [
    "X_train_vi = np.load('X_train_vi.npy')\n",
    "X_test_vi = np.load('X_test_vi.npy')\n",
    "X_train_th = np.load('X_train_th.npy')\n",
    "X_test_th = np.load('X_test_th.npy')\n",
    "\n",
    "\n",
    "X_train = np.concatenate((X_train_vi,X_train_th),axis=1)\n",
    "X_test = np.concatenate((X_test_vi,X_test_th),axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "np.save('X_train.npy',X_train)\n",
    "np.save('X_test.npy',X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifieurs  \n",
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 3, 26, 6]\n",
      "Non conformes : 43\n",
      "Conformes : 29\n",
      "taux de faux conformes par rapport aux non conformes : 0.13953488372093023\n",
      "score = 0.875\n",
      "score du random = 0.5972222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "Y_test = np.load('Y_test.npy')\n",
    "\n",
    "\n",
    "LDA.fit(X_train,Y_train)\n",
    "Y_pred = LDA.predict(X_test)\n",
    "\n",
    "def matrice_confusion(pred,lab):\n",
    "\t#calcul des vrais positifs\n",
    "\tvp = np.count_nonzero((pred == 1) & (lab == 1))\n",
    "\t#calculs des faux positifs\n",
    "\tfp = np.count_nonzero((pred == 1) & (lab == 0))\n",
    "\t#calculs des vrais négatifs\n",
    "\tvn = np.count_nonzero((pred == 0) & (lab == 0))\n",
    "\t#calculs des faux négatifs\n",
    "\tfn = np.count_nonzero((pred == 0) & (lab == 1))\n",
    "\treturn [vp,fp,vn,fn]\n",
    "\t\n",
    "conf = matrice_confusion(Y_pred,Y_test)\n",
    "print(conf)\n",
    "taux_fn = conf[3]/sum(conf)\n",
    "taux_fn_neg = conf[3]/(conf[3]+conf[0])\n",
    "non_conf = conf[0]+conf[3]\n",
    "conf = conf[1]+conf[2]\n",
    "\n",
    "score_random = max(conf/(conf+non_conf),non_conf/(conf+non_conf))\n",
    "\n",
    "print(f\"Non conformes : {non_conf}\")\n",
    "print(f\"Conformes : {conf}\")\n",
    "print(f\"taux de faux conformes par rapport aux non conformes : {taux_fn_neg}\")\n",
    "\n",
    "print(f\"score = {LDA.score(X_test,Y_test)}\")\n",
    "print(f\"score du random = {score_random}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 1, 28, 2]\n",
      "Non conformes : 43\n",
      "Conformes : 29\n",
      "taux de faux conformes par rapport aux non conformes : 0.046511627906976744\n",
      "score = 0.9583333333333334\n",
      "score du random = 0.5972222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "Y_test = np.load('Y_test.npy')\n",
    "\n",
    "neigh.fit(X_train,Y_train)\n",
    "Y_pred = neigh.predict(X_test)\n",
    "\n",
    "conf = matrice_confusion(Y_pred,Y_test)\n",
    "print(conf)\n",
    "taux_fn = conf[3]/sum(conf)\n",
    "taux_fn_neg = conf[3]/(conf[3]+conf[0])\n",
    "non_conf = conf[0]+conf[3]\n",
    "conf = conf[1]+conf[2]\n",
    "\n",
    "score_random = max(conf/(conf+non_conf),non_conf/(conf+non_conf))\n",
    "\n",
    "print(f\"Non conformes : {non_conf}\")\n",
    "print(f\"Conformes : {conf}\")\n",
    "print(f\"taux de faux conformes par rapport aux non conformes : {taux_fn_neg}\")\n",
    "\n",
    "print(f\"score = {neigh.score(X_test,Y_test)}\")\n",
    "print(f\"score du random = {score_random}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train = 1 sur 5, X_test = le reste  \n",
    "#### 1-NN :  \n",
    "[76, 7, 56, 4]  \n",
    "Non conformes : 80  \n",
    "Conformes : 63  \n",
    "taux de faux conformes par rapport aux non conformes : 0.05  \n",
    "score = 0.9230769230769231  \n",
    "score du random = 0.5594405594405595    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-NN : \n",
    "[52, 0, 63, 28]  \n",
    "Non conformes : 80  \n",
    "Conformes : 63  \n",
    "taux de faux conformes par rapport aux non conformes : 0.35  \n",
    "score = 0.8041958041958042  \n",
    "score du random = 0.5594405594405595   \n",
    "#### 3-NN :  \n",
    "[58, 8, 55, 22]  \n",
    "Non conformes : 80   \n",
    "Conformes : 63  \n",
    "taux de faux conformes par rapport aux non conformes : 0.275  \n",
    "score = 0.7902097902097902  \n",
    "score du random = 0.5594405594405595    \n",
    "#### 4-NN :  \n",
    "[52, 0, 63, 28]  \n",
    "Non conformes : 80  \n",
    "Conformes : 63  \n",
    "taux de faux conformes par rapport aux non conformes : 0.35  \n",
    "score = 0.8041958041958042  \n",
    "score du random = 0.5594405594405595  \n",
    "#### 5-NN :  \n",
    "[60, 8, 55, 20]  \n",
    "Non conformes : 80  \n",
    "Conformes : 63  \n",
    "taux de faux conformes par rapport aux non conformes : 0.25  \n",
    "score = 0.8041958041958042  \n",
    "score du random = 0.5594405594405595    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de jeux random satisfaisant la proportion 70 train 30 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-NN: \n",
    "[28, 0, 24, 2]  \n",
    "Non conformes : 30  \n",
    "Conformes : 24  \n",
    "taux de faux conformes par rapport aux non conformes : 0.06666666666666667  \n",
    "score = 0.9629629629629629  \n",
    "score du random = 0.5555555555555556  \n",
    "#### 2-NN:  \n",
    "[28, 0, 24, 2]  \n",
    "Non conformes : 30  \n",
    "Conformes : 24  \n",
    "taux de faux conformes par rapport aux non conformes : 0.06666666666666667  \n",
    "score = 0.9629629629629629  \n",
    "score du random = 0.5555555555555556  \n",
    "#### 3-NN: \n",
    "[29, 1, 23, 1]  \n",
    "Non conformes : 30  \n",
    "Conformes : 24  \n",
    "taux de faux conformes par rapport aux non conformes : 0.03333333333333333  \n",
    "score = 0.9629629629629629  \n",
    "score du random = 0.5555555555555556   \n",
    "#### 4-NN:  \n",
    "[28, 0, 24, 2]  \n",
    "Non conformes : 30  \n",
    "Conformes : 24  \n",
    "taux de faux conformes par rapport aux non conformes : 0.06666666666666667  \n",
    "score = 0.9629629629629629  \n",
    "score du random = 0.5555555555555556  \n",
    "#### 5-NN:  \n",
    "[29, 1, 23, 1]  \n",
    "Non conformes : 30  \n",
    "Conformes : 24  \n",
    "taux de faux conformes par rapport aux non conformes : 0.03333333333333333  \n",
    "score = 0.9629629629629629  \n",
    "score du random = 0.5555555555555556  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de jeux qui séparent les différents essais:  \n",
    "num_piece pair : test  \n",
    "num_piece impair : train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-NN: \n",
    "[40, 11, 19, 14]  \n",
    "Non conformes : 54  \n",
    "Conformes : 30  \n",
    "taux de faux conformes par rapport aux non conformes : 0.25925925925925924  \n",
    "score = 0.7023809523809523  \n",
    "score du random = 0.6428571428571429  \n",
    "#### 2-NN:  \n",
    "[36, 11, 19, 18]  \n",
    "Non conformes : 54  \n",
    "Conformes : 30  \n",
    "taux de faux conformes par rapport aux non conformes : 0.3333333333333333  \n",
    "score = 0.6547619047619048  \n",
    "score du random = 0.6428571428571429  \n",
    "#### 3-NN:  \n",
    "[38, 11, 19, 16]  \n",
    "Non conformes : 54  \n",
    "Conformes : 30  \n",
    "taux de faux conformes par rapport aux non conformes : 0.2962962962962963  \n",
    "score = 0.6785714285714286  \n",
    "score du random = 0.6428571428571429  \n",
    "#### 4-NN:\n",
    "[36, 11, 19, 18]  \n",
    "Non conformes : 54  \n",
    "Conformes : 30  \n",
    "taux de faux conformes par rapport aux non conformes : 0.3333333333333333  \n",
    "score = 0.6547619047619048  \n",
    "score du random = 0.6428571428571429  \n",
    "#### 5-NN:  \n",
    "[36, 11, 19, 18]  \n",
    "Non conformes : 54  \n",
    "Conformes : 30  \n",
    "taux de faux conformes par rapport aux non conformes : 0.3333333333333333  \n",
    "score = 0.6547619047619048  \n",
    "score du random = 0.6428571428571429  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de jeux random 60% train, 40% test\n",
    "### 1er test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-NN:  \n",
    "[41, 2, 27, 2]  \n",
    "Non conformes : 43  \n",
    "Conformes : 29  \n",
    "taux de faux conformes par rapport aux non conformes : 0.046511627906976744  \n",
    "score = 0.9444444444444444  \n",
    "score du random = 0.5972222222222222  \n",
    "#### 2-NN:  \n",
    "[41, 2, 27, 2]  \n",
    "Non conformes : 43  \n",
    "Conformes : 29  \n",
    "taux de faux conformes par rapport aux non conformes : 0.046511627906976744  \n",
    "score = 0.9444444444444444  \n",
    "score du random = 0.5972222222222222  \n",
    "#### 3-NN:  \n",
    "[41, 2, 27, 2]  \n",
    "Non conformes : 43  \n",
    "Conformes : 29  \n",
    "taux de faux conformes par rapport aux non conformes : 0.046511627906976744  \n",
    "score = 0.9444444444444444  \n",
    "score du random = 0.5972222222222222  \n",
    "#### 4-NN:  \n",
    "[40, 2, 27, 3]  \n",
    "Non conformes : 43  \n",
    "Conformes : 29  \n",
    "taux de faux conformes par rapport aux non conformes : 0.06976744186046512  \n",
    "score = 0.9305555555555556  \n",
    "score du random = 0.5972222222222222  \n",
    "#### 5-NN:\n",
    "[41, 2, 27, 2]  \n",
    "Non conformes : 43  \n",
    "Conformes : 29  \n",
    "taux de faux conformes par rapport aux non conformes : 0.046511627906976744  \n",
    "score = 0.9444444444444444  \n",
    "score du random = 0.5972222222222222  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2eme test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-NN :\n",
    "taux de faux conformes par rapport aux non conformes : 0.07894736842105263  \n",
    "score = 0.9305555555555556  \n",
    "score du random = 0.5277777777777778  \n",
    "#### 2-NN :\n",
    "taux de faux conformes par rapport aux non conformes : 0.15789473684210525  \n",
    "score = 0.9027777777777778    \n",
    "score du random = 0.5277777777777778  \n",
    "#### 3-NN :\n",
    "taux de faux conformes par rapport aux non conformes : 0.15789473684210525  \n",
    "score = 0.9027777777777778  \n",
    "score du random = 0.5277777777777778  \n",
    "#### 4-NN :\n",
    "taux de faux conformes par rapport aux non conformes : 0.15789473684210525  \n",
    "score = 0.9027777777777778  \n",
    "score du random = 0.5277777777777778  \n",
    "#### 5-NN :\n",
    "taux de faux conformes par rapport aux non conformes : 0.15789473684210525  \n",
    "score = 0.9027777777777778  \n",
    "score du random = 0.5277777777777778  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3eme test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-NN:\n",
    "taux de faux conformes par rapport aux non conformes : 0.023255813953488372  \n",
    "score = 0.9583333333333334  \n",
    "score du random = 0.5972222222222222  \n",
    "#### 2-NN:\n",
    "taux de faux conformes par rapport aux non conformes : 0.023255813953488372  \n",
    "score = 0.9722222222222222  \n",
    "score du random = 0.5972222222222222  \n",
    "#### 3-NN:\n",
    "taux de faux conformes par rapport aux non conformes : 0.023255813953488372  \n",
    "score = 0.9722222222222222  \n",
    "score du random = 0.5972222222222222  \n",
    "#### 4-NN:\n",
    "taux de faux conformes par rapport aux non conformes : 0.046511627906976744  \n",
    "score = 0.9583333333333334  \n",
    "score du random = 0.5972222222222222  \n",
    "#### 5-NN:\n",
    "taux de faux conformes par rapport aux non conformes : 0.046511627906976744  \n",
    "score = 0.9583333333333334    \n",
    "score du random = 0.5972222222222222  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score et taux moyens :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-NN:\n",
    "score : 0.942  \n",
    "taux : 0.049\n",
    "#### 2-NN:\n",
    "score :  0.936  \n",
    "taux :  0.075  \n",
    "#### 3-NN:\n",
    "score : 0.939  \n",
    "taux : 0.075\n",
    "#### 4-NN:\n",
    "#### 5-NN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cf901583f7627b34116b014bc4696893c62b0255ab3e3e7cbe11c042920c781"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
